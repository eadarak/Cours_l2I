Y
Y=sum(ski_Y)
X=sum(ski_X)
X2=sum(ski_X*ski_X)
Y2=sum(ski_Y*ski_Y)
XY=sum(ski_X*ski_Y)
XY2= X*Y
XY2
# somme des xi = 53000; somme des yi = 2200; produit xiyi = 12102000
# somme des yi^2 = 498800 ; somme des xi^2 =  294740000;
# Calcule de l'intercept b
#on donne : b= cov(X,Y)/Var(X) <==> b=(∑Xi-(∑Yi*∑Xi)\n)\(∑X^2-(∑X^2\n));
cov=(X-((X*Y)/10))
cov
# somme des xi = 53000; somme des yi = 2200; produit xiyi = 12102000
# somme des yi^2 = 498800 ; somme des xi^2 =  294740000;
# Calcule de l'intercept b
#on donne : b= cov(X,Y)/Var(X) <==> b=(∑Xi-(∑Yi*∑Xi)\n)\(∑X^2-(∑X^2\n));
covXY=(X-((X*Y)/10))
varX=(X2-((X*X)/10))
varX
b=covXY/varX
b
round(varX,-4)
varX=round((X2-((X*X)/10)),digits = 4)
#varX=round((X2-((X*X)/10)),digits = 4)
X*X
#varX=round((X2-((X*X)/10)),digits = 4)
round(X*X,digits=2)
#varX=round((X2-((X*X)/10)),digits = 4)
round(X*X,digits=-2)
varX=round((X2-(2809*exp(6)/10)),digits = 4)
varX
varX=(X2-((53000*53000)/10))
varX
varX=(X2-((X*X)/10))
X
X*X
prod(X*X)
lm(ski_X~ski_Y)
b=covXY/varX
b
varX=(X2-(53000*53000)/10))
varX=(X2-((53000*53000)/10))
varX
# somme des xi = 53000; somme des yi = 2200; produit xiyi = 12102000
# somme des yi^2 = 498800 ; somme des xi^2 =  294740000;
# Calcule de l'intercept b
#on donne : b= cov(X,Y)/Var(X) <==> b=(∑Xi-(∑Yi*∑Xi)\n)\(∑X^2-(∑X^2\n));
covXY=(X-((X*Y)/10))
# somme des xi = 53000; somme des yi = 2200; produit xiyi = 12102000
# somme des yi^2 = 498800 ; somme des xi^2 =  294740000;
# Calcule de l'intercept b
#on donne : b= cov(X,Y)/Var(X) <==> b=(∑Xi-(∑Yi*∑Xi)\n)\(∑X^2-(∑X^2\n));
covXY=(X-((X*Y)/10))
covXY
covXY/varX
lm(ski_Y~ski_X)
skidata = read.table("C:/Users/El Abdou DRAME/Desktop/L2I-2021_officiel/DEUXIEME ANNEE/Analyse de Donnes/Cours-AD-Licence-Info/td/ski.txt", header = TRUE)
ski=skidata[-1]
ski_X= ski[[1]]
ski_Y = ski[[2]]
x=sum(ski_X)
y=sum(ski_Y)
xy=sum(ski_X*ski_Y)
x2=sum(ski_X*ski_X)
y2=sum(ski_Y*ski_Y)
xy
x2
x_bar=x/n
y_bar=y/n
#d'apres le nuage de point les variables semblent etre lineaire.
#l'augmentation de nombre d'accident depend du nombre de skieurs
# somme des xi = 53000; somme des yi = 2200; produit xiyi = 12102000
# somme des yi^2 = 498800 ; somme des xi^2 =  294740000;
n=10
x_bar=x/n
y_bar=y/n
x_bar
y_bar
# calcule de la pente
# on donne b= cov(x,y)/var(x)
# avec cov(x,y)=(∑xiyi/n)-X_br*Y_br et var(x)=(∑xi²/n )- x_bar²
covXY=(xy/n)-x_bar*y_bar
covXY
varX= (x2/n)- x_bar*x_bar
var x
varX
b=covXY/varX
b
lm(ski_X~ski_Y)
lm(ski_Y~ski_X)
b=round(b, digits = 4)
b
# nous constatons que la pente b =0.0319
# calculons l'intercept a
# on donne a = x_br - b * Y_bar
a= x_bar - b * y_bar
skidata = read.table("C:/Users/El Abdou DRAME/Desktop/L2I-2021_officiel/DEUXIEME ANNEE/Analyse de Donnes/Cours-AD-Licence-Info/td/ski.txt", header = TRUE)
ski=skidata[-1]
ski_X= ski[[1]]
ski_Y = ski[[2]]
n=10
x=sum(ski_X)
y=sum(ski_Y)
xy=sum(ski_X*ski_Y)
x2=sum(ski_X*ski_X)
y2=sum(ski_Y*ski_Y)
x_bar=x/n
y_bar=y/n
covXY=(xy/n)-x_bar*y_bar
varX= (x2/n)- x_bar*x_bar
b=covXY/varX
b=round(b, digits = 4)
# nous constatons que la pente b =0.0319
# calculons l'intercept a
# on donne a = x_br - b * Y_bar
a= x_bar - b * y_bar
a
sum((ski_Y-y_bar)*(ski_X*x_bar))
num=sum((ski_Y-y_bar)*(ski_X*x_bar))
num=sum((ski_Y-y_bar)*(ski_X-x_bar))
num
den=sum((ski_X-x_bar)*(ski_X-x_bar))
den
num/den
y_bar-(num/den)*x_bar
b=covXY/varX
# nous constatons que la pente b =0.0319
# calculons l'intercept a
# on donne a = x_br - b * Y_bar
a= x_bar - b * y_bar
a
# nous constatons que la pente b =0.0319
# calculons l'intercept a
# on donne a = x_br - b * Y_bar
a= x_bar-b*y_bar
# nous constatons que la pente b =0.0319
# calculons l'intercept a
# on donne a = x_br - b * Y_bar
a=x_bar-b*y_bar
b
# nous constatons que la pente b =0.0319
# calculons l'intercept a
# on donne a = x_br - b * Y_bar
a=y_bar-b*x_bar
a
#d'apres le nuage de point les variables semblent etre lineaire.
cor(ski_X,ski_Y)
50.736950.7369
svnvxc
# le coefficient de corrélation r= 0.9766149 qui est
# proche de 1 montre les deux variables sont fortement corrélées.
cor.test(ski_X,ski_Y)
summary(lm(ski_Y~ski_X))
# En tapant result dans la console,Nous constatont que
#l'ordonnée à l'origine est egale à 50.7369
#et la pente est de   0.031936 < 5%, donc la pente est significative
# donc on peut la laisser dans la regression.
# En visualisant le R-squared ajustee on constate que 0.948
#Ainsi on peut dire que 94,8% de la variance est due à la régression
# ou encore 74,6% du nombre d'accident est expliqué par le nombre de skieurs.
##
# d'ou le modele est adequate.
abline(lm(ski_Y~ski_X))
# En tapant result dans la console,Nous constatont que
#l'ordonnée à l'origine est egale à 50.7369
#et la pente est de   0.031936 < 5%, donc la pente est significative
# donc on peut la laisser dans la regression.
# En visualisant le R-squared ajustee on constate que 0.948
#Ainsi on peut dire que 94,8% de la variance est due à la régression
# ou encore 74,6% du nombre d'accident est expliqué par le nombre de skieurs.
##
# d'ou le modele est adequate.
abline(lm(ski_Y~ski_X), col="red")
resid = result$residuals
plot(resid,ylab="Nombres d'accident ",xlab="",main="Variations
nombre d'accident en fonction du nombre de skieurs")
abline(h=0,col="red")
resid = lm(ski_Y~ski_X)$residuals
abline(lm(ski_Y~ski_X), col="red")
resid = lm(ski_Y~ski_X)$residuals
plot(resid,ylab="Nombres d'accident ",xlab="",main="Variations
nombre d'accident en fonction du nombre de skieurs")
abline(h=0,col="red")
abline(lm(ski_Y~ski_X), col="red")
abline(lm(ski_Y~ski_X), col="red")
plot(ski_X,ski_Y,xlab="Xi",ylab="Yi")
abline(lm(ski_Y~ski_X), col="red")
basePIB = read.csv2("C:/Users/El Abdou DRAME/Desktop/L2I-2021_officiel/DEUXIEME ANNEE/Analyse de Donnes/Cours-AD-Licence-Info/Donnees/basePIB.csv")
View(basePIB)
View(ski)
###
new=data.frame(Xi=8000,Yi=270)
View(new)
AX = predict(reg,ski = new,se.fit = TRUE)
AX = predict(reg,newdata= new,se.fit = TRUE)
# pour retrouver ces resultats on tape la commande lm(y~x)
result=lm(ski_Y~ski_X)
summary(result)
###
new=data.frame(Xi=8000,Yi=270)
AX = predict(result,newdata= new,se.fit = TRUE)
abline(result, col="red")
AX = predict(result,newdata= new,se.fit = TRUE)
AX$fit
AX = predict(result,newdata=new,se.fit = TRUE)
AX$fit
pnb = read.table("C:/Users/El Abdou DRAME/Desktop/L2I-2021_officiel/DEUXIEME ANNEE/Analyse de Donnes/Cours-AD-Licence-Info/td/pnb.txt", header = TRUE)
View(pnb)
pnbdata=data.frame(pnb,cons.prive)
pnb = read.table("C:/Users/El Abdou DRAME/Desktop/L2I-2021_officiel/DEUXIEME ANNEE/Analyse de Donnes/Cours-AD-Licence-Info/td/pnb.txt", header = TRUE)
pnb = read.table("C:/Users/El Abdou DRAME/Desktop/L2I-2021_officiel/DEUXIEME ANNEE/Analyse de Donnes/Cours-AD-Licence-Info/td/pnb.txt", header = TRUE)
pnbdata=data.frame(pnb,cons)
pnbdata=pnb[[-1]]
pnbdata=pnb[[-1]]
pnbdata=pnb[-1]
ski=edit(ski)#saisir les donnees de la base SKI
# Correction td 1
#Saisir les donnees sous forme data.frame
ski = data.frame()#creer la base de donnee
View(ski)
View(ski)
View(ski)
View(ski)
View(ski)
View(ski)
ski=edit(ski)#saisir les donnees de la base SKI
skidata = read.table("C:/Users/El Abdou DRAME/Desktop/L2I-2021_officiel/DEUXIEME ANNEE/Analyse de Donnes/Cours-AD-Licence-Info/td/ski.txt", header = TRUE)
ski=skidata[-1]
ski_X= ski[[1]]
ski_Y = ski[[2]]
plot(ski_X,ski_Y,xlab="Nombre de skieur",ylab="Nombre d'accident")
#d'apres le nuage de point les variables semblent etre lineaire.
cor(ski_X,ski_Y)
# le coefficient de corrélation r= 0.9766149 qui est
# proche de 1 montre les deux variables sont fortement corrélées.
cor.test(ski_X,ski_Y)
#le p_value est inferieure a 5% donc au seuil de 5 %
#l'augmentation du nombre de skieurs entraine l'augmentation du nombre d'accident
# somme des xi = 53000; somme des yi = 2200; produit xiyi = 12102000
# somme des yi^2 = 498800 ; somme des xi^2 =  294740000;
n=10
x=sum(ski_X)
y=sum(ski_Y)
xy=sum(ski_X*ski_Y)
x2=sum(ski_X*ski_X)
y2=sum(ski_Y*ski_Y)
x_bar=x/n
y_bar=y/n
plot(ski_X,ski_Y,xlab="Nombre de skieur",ylab="Nombre d'accident", col="red")
result=lm(ski_Y~ski_X)
summary(result)
skidata = read.table("C:/Users/El Abdou DRAME/Desktop/L2I-2021_officiel/DEUXIEME ANNEE/Analyse de Donnes/Cours-AD-Licence-Info/td/ski.txt", header = TRUE)
ski=skidata[-1]
ski_X= ski[[1]]
ski_Y = ski[[2]]
n=10
x=sum(ski_X)
y=sum(ski_Y)
xy=sum(ski_X*ski_Y)
x2=sum(ski_X*ski_X)
y2=sum(ski_Y*ski_Y)
x_bar=x/n
y_bar=y/n
covXY=(xy/n)-x_bar*y_bar
varX= (x2/n)- x_bar*x_bar
b=covXY/varX
b=round(b, digits = 4)
#num=sum((ski_Y-y_bar)*(ski_X-x_bar))
#den=sum((ski_X-x_bar)*(ski_X-x_bar))
# nous constatons que la pente b =0.0319
# calculons l'intercept a
# on donne a = x_br - b * Y_bar
a=y_bar-b*x_bar
# pour retrouver ces resultats on tape la commande lm(y~x)
result=lm(ski_Y~ski_X)
summary(result)
result$coefficients
b=covXY/varX
b=round(b, digits = 4)
#10- Prevision du nombre d'accident pour X=8000
#pour determinere la prevision on prend l'ordonnee a l'origine ou l'intercept
#
y11= 50.93 + 0.0319*8000
# intervalle de confiance on utilise la fonction predict
predict(result, newdata = c(8000,270))
# intervalle de confiance on utilise la fonction predict
predict(result, newdata = c(8000,270), se.fit = TRUE)
View(pnbdata)
View(ski)
newx=data.frame(ski_X=8000)
predict(result, newdata =newx
newx=data.frame(ski_X=8000)
predict(result, newdata =newx
predict(result, newdata =newx, interval = "prediction", level=0.95)
# intervalle de confiance on utilise la fonction predict
newx=data.frame(ski_X=8000)
predict(result, newdata =newx, interval = "prediction", level=0.95)
# on sait que r^2=R^2 donc la correlation r sera egale a
# - racine carre de R^2 vu que la corellation est negatif.
r= - sqrt(R2)
0.72
# on sait que r^2=R^2 donc la correlation r sera egale a
# - racine carre de R^2 vu que la corellation est negatif.
r= - sqrt(R2)
# on note que la correlation est negatif
#1-
R2=0.72
# on sait que r^2=R^2 donc la correlation r sera egale a
# - racine carre de R^2 vu que la corellation est negatif.
r= -1 *sqrt(R2)
#on donne r=(Sx/Sy)*b donc b=r*(Sy/Sx)
#la pente est :
b= (r*Sy)/Sx
mx=0.308
Sx=0.267 #ecart-type
my=0.388
Sy=19.6
#on donne r=(Sx/Sy)*b donc b=r*(Sy/Sx)
#la pente est :
b= (r*Sy)/Sx
# on sait que a= my-bmx;
a=my-b*mx
mx=0.308
Sx=0.267 #ecart-type
my=0.388
Sy=0.196
# on note que la correlation est negatif
#1-
R2=0.72
# on sait que r^2=R^2 donc la correlation r sera egale a
# - racine carre de R^2 vu que la corellation est negatif.
r= -1 *sqrt(R2)
## Conclusion:
## r=-0.849 ==> les deux variable sont fortement et negativement correlee
#2- Calculons l'intercept et la pente
#on donne r=(Sx/Sy)*b donc b=r*(Sy/Sx)
b= (r*Sy)/Sx # la pente = -62.28
r= round(r, digits = 3)
mx=0.308
Sx=0.267 #ecart-type
my=0.388
Sy=0.196
# on note que la correlation est negatif
#1-
R2=0.72
# on sait que r^2=R^2 donc la correlation r sera egale a
# - racine carre de R^2 vu que la corellation est negatif.
r= -1 *sqrt(R2)
r= round(r, digits = 3)
#on donne r=(Sx/Sy)*b donc b=r*(Sy/Sx)
b= (r*Sy)/Sx # la pente = -62.28
Sy=0.169
#on donne r=(Sx/Sy)*b donc b=r*(Sy/Sx)
b= (r*Sy)/Sx # la pente = -62.28
#on donne r=(Sx/Sy)*b donc b=r*(Sy/Sx)
b= round(((r*Sy)/Sx), digits = 3) # la pente = -62.28
b
# on sait que a= my-bmx;
a=my-b*mx
# on sait que a= my-bmx;
a=round((my-b*mx),digits=3)
# donc la droite de regression y = a+bx
y=a+bx
x13=0.4
y13=0.4
#calculer la valeur de la residu
E13= y13-y13_chapeau
#on sait
y13_chapeau= a+b*y13
#calculer la valeur de la residu
E13= y13-y13_chapeau
# on sait que a= my-bmx;
a=round((my-b*mx),digits=3) # l'intercep = 0.533
q
mx=0.308
Sx=0.267 #ecart-type
my=0.388
Sy=0.169
# on note que la correlation est negatif
#1-
R2=0.72
# on sait que r^2=R^2 donc la correlation r sera egale a
# - racine carre de R^2 vu que la corellation est negatif.
r= -1 *sqrt(R2)
r= round(r, digits = 3)
## Conclusion:
## r=-0.849 ==> les deux variable sont fortement et negativement correlee
#2- Calculons l'intercept et la pente
#on donne r=(Sx/Sy)*b donc b=r*(Sy/Sx)
b= round(((r*Sy)/Sx), digits = 3) # la pente = -0.537
# on sait que a= my-bmx;
a=round((my-b*mx),digits=3) # l'intercep = 0.533
# donc la droite de regression y = a+bx
#3- Interpretation de la valeur de l'intercept
# a=0.533 ==> a l'absence d'aide sociale, %53,3% des cyclistes portes des casques.
#  x= aide sociale , y= cycliste portant une casque.
#4-
# b=-0.537 => l'aide sociale defavorise le port de casque.
##Interpretation de la pente en cas general:
#y=a+bx ==> Une augmentation d'une unite de x va entrainer
# une augmentation de b unite de y(si b>0).
## Dans notre cas , l'augmentation d'une unite sociale entraine
# la dimunition de 0.537 du port de casque.Donc l'aide sociale
# defavorise le port de casque.
#5-
x13=0.4
y13=0.4 # ceci est la valeur observee
#on sait
y13_chapeau= a+b*y13 #  ceci est la valeur predite
#calculer la valeur de la residu
E13= y13-y13_chapeau
# le residu mesure la valeur observe a la valeur qu'on aurait du observe
# on la residu = 0.0618
##conclusion:
# => le residu mesure l'ecart entre la valeur observe et la valeur
#predite . La valeur du residu esr]t faible soit 6,18%
a
b
result$coefficients#$coefficient permet d'afficher que les coefficient.
skidata = read.table("C:/Users/El Abdou DRAME/Desktop/L2I-2021_officiel/DEUXIEME ANNEE/Analyse de Donnes/Cours-AD-Licence-Info/td/ski.txt", header = TRUE)
ski=skidata[-1]
ski_X= ski[[1]]
ski_Y = ski[[2]]
plot(ski_X,ski_Y,xlab="Nombre de skieur",ylab="Nombre d'accident", col="red")
#d'apres le nuage de point les variables semblent etre lineaire.
cor(ski_X,ski_Y)
# le coefficient de corrélation r= 0.9766149 qui est
# proche de 1 montre les deux variables sont fortement corrélées.
cor.test(ski_X,ski_Y)
#le p_value est inferieure a 5% donc au seuil de 5 %
#l'augmentation du nombre de skieurs entraine l'augmentation du nombre d'accident
# somme des xi = 53000; somme des yi = 2200; produit xiyi = 12102000
# somme des yi^2 = 498800 ; somme des xi^2 =  294740000;
n=10
x=sum(ski_X)
y=sum(ski_Y)
xy=sum(ski_X*ski_Y)
x2=sum(ski_X*ski_X)
y2=sum(ski_Y*ski_Y)
x_bar=x/n
y_bar=y/n
# calcule de la pente
# on donne b= cov(x,y)/var(x)
# avec cov(x,y)=(???xiyi/n)-X_br*Y_br et var(x)=(???xi²/n )- x_bar²
covXY=(xy/n)-x_bar*y_bar
varX= (x2/n)- x_bar*x_bar
b=covXY/varX
b=round(b, digits = 4)
#num=sum((ski_Y-y_bar)*(ski_X-x_bar))
#den=sum((ski_X-x_bar)*(ski_X-x_bar))
# nous constatons que la pente b =0.0319
# calculons l'intercept a
# on donne a = x_br - b * Y_bar
a=y_bar-b*x_bar
# nous constatons que l'intercept a=50.7369
# pour retrouver ces resultats on tape la commande lm(y~x)
result=lm(ski_Y~ski_X)
result$coefficients#$coefficient permet d'afficher que les coefficient.
summary(result)
# En tapant result dans la console,Nous constatont que
#l'ordonnée à l'origine est egale à 50.7369
#et la pente est de   0.031936 < 5%, donc la pente est significative
# donc on peut la laisser dans la regression.
# En visualisant le R-squared ajustee on constate que 0.948
#Ainsi on peut dire que 94,8% de la variance est due à la régression
# ou encore 74,6% du nombre d'accident est expliqué par le nombre de skieurs.
##
# d'ou le modele est adequate.
abline(result, col="red")
#resid = lm(ski_Y~ski_X)$residuals
#plot(resid,ylab="Nombres d'accident ",xlab="",main="Variations
#nombre d'accident en fonction du nombre de skieurs")
#abline(h=0,col="red")
###
new=data.frame(Xi=8000,Yi=270)
AX = predict(result,newdata=new,se.fit = TRUE)
AX$fit
###################################################################
#6- on veut tester l'hypothese H0: b=0 la pente n'est pas significative
# et l'hypothese h1: la pente est significative. ==> teste de significativite de
#la pente.
#pour cela on utilisera la fonction lm(Y~X), et la fonction summary
#puis un regarde la p.value  ou Pr(>|t|);
##conclusion:
#P.value=1.27e-06 <5%, donc on rejette H0
#avec un risque de 5%, la pente est signicative
#7- L'ajustement:
# s'il s'agit d'un regression lineaire simple on peut utiliser Multiple R-squared
# Et s'il s'agit de regression lineaire multiple on prefere utiliser
# Adjusted R-squared.car la regression est sensible a l'ajout de variable.
#8-aduequation du modele
#le modele ajuste bien les donnees car le coefficient de determination=95,3% d'ou
#95% des donnees est explique par le modele
#10- Prevision du nombre d'accident pour X=8000
#pour determiner la prevision on prend l'ordonnee a l'origine ou l'intercept
#
y11= 50.93 + 0.0319*8000
# intervalle de confiance on utilise la fonction predict
newx=data.frame(ski_X=8000)
predict(result, newdata =newx, interval = "prediction", level=0.95)
##Pour x=8000 le nombre d'accident est estimer a 306.
# la prevision ponctuelle est que
result$coefficients#$coefficient permet d'afficher que les coefficient.
result$residuals
summary(result)
#10- Prevision du nombre d'accident pour X=8000
#pour determiner la prevision on prend l'ordonnee a l'origine ou l'intercept
#
y11= 50.93 + 0.0319*8000
y11
